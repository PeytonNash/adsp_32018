{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eed455b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /Users/peytonnash/Documents/university_of_chicago/04_summ_25/adsp_32018/.venv/lib/python3.10/site-packages (3.10.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/peytonnash/Documents/university_of_chicago/04_summ_25/adsp_32018/.venv/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/peytonnash/Documents/university_of_chicago/04_summ_25/adsp_32018/.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/peytonnash/Documents/university_of_chicago/04_summ_25/adsp_32018/.venv/lib/python3.10/site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/peytonnash/Documents/university_of_chicago/04_summ_25/adsp_32018/.venv/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/peytonnash/Documents/university_of_chicago/04_summ_25/adsp_32018/.venv/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/peytonnash/Documents/university_of_chicago/04_summ_25/adsp_32018/.venv/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/peytonnash/Documents/university_of_chicago/04_summ_25/adsp_32018/.venv/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/peytonnash/Documents/university_of_chicago/04_summ_25/adsp_32018/.venv/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/peytonnash/Documents/university_of_chicago/04_summ_25/adsp_32018/.venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/peytonnash/Documents/university_of_chicago/04_summ_25/adsp_32018/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q \"numpy<2\" \\\n",
    "    scipy==1.12.0 \\\n",
    "    gensim==4.3.1 \\\n",
    "    pyLDAvis==3.4.1 \\\n",
    "    spacy==3.7.2\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57903547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import string\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spacy\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models import Phrases, LdaModel, LdaMulticore, CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5938a8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 11 workers\n"
     ]
    }
   ],
   "source": [
    "num_processors = mp.cpu_count()\n",
    "print(f'Using {num_processors} workers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8e7fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the CSV\n",
    "df = pd.read_parquet('clean1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8adbca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function from Nick for cleaning the data\n",
    "def clean_text(corpus, spacy_pipeline, as_string=True, n_proc=2, batch_size=200):\n",
    "    \"\"\"\n",
    "    Cleans a sequence of text by applying some simple processing techniques.\n",
    "\n",
    "    Args:\n",
    "        corpus (Iterable): a sequence of text to be processed\n",
    "        spacy_pipeline: the Spacy pipeline object for processing text\n",
    "        n_proc (int): the number of processors to use for parallel processing\n",
    "        batch_size (int): the number of texts to process in a single batch\n",
    "\n",
    "    Returns:\n",
    "        clean_sequence (list): a cleaned version of the original text\n",
    "    \"\"\"\n",
    "    # container to store cleaned documents\n",
    "    corpus_clean = []\n",
    "\n",
    "    for doc in spacy_pipeline.pipe(\n",
    "        corpus,\n",
    "        disable=[\"ner\"],\n",
    "        n_process=n_proc,\n",
    "        batch_size=batch_size\n",
    "    ):\n",
    "\n",
    "        # container for cleaned document tokens\n",
    "        doc_tokens = [\n",
    "            token.lemma_.lower()\n",
    "            for token in doc\n",
    "            if not token.is_stop and token.is_alpha and (len(token) > 1) and token.pos_ in (\"NOUN\", \"VERB\") # should consider if these are appropriate\n",
    "        ]\n",
    "        \n",
    "        if as_string:\n",
    "            corpus_clean.append(\" \".join(doc_tokens))\n",
    "        else:\n",
    "            corpus_clean.append(doc_tokens)\n",
    "\n",
    "    return corpus_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f1ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spaCy model\n",
    "spacy.cli.download(\"en_core_web_md\")\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f25bc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(88369) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(88370) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(88372) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(88373) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(88374) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "# Clean the dataset\n",
    "normalized_corpus = clean_text(\n",
    "    corpus=df[\"text_clean\"].tolist(),\n",
    "    spacy_pipeline=nlp,\n",
    "    as_string=False,\n",
    "    n_proc=int(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a13bb9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.DataFrame(normalized_corpus)\n",
    "df_clean.to_parquet('clean_lda.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca63fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary\n",
    "dictionary = Dictionary(normalized_corpus)\n",
    "\n",
    "# Filter out words rare or common words\n",
    "dictionary.filter_extremes(no_below=0.01*len(normalized_corpus), no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f605b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in normalized_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea1d6111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Nick's function for calculating coherence score\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    lda_model = LdaMulticore(corpus=corpus,\n",
    "                       id2word=dictionary,\n",
    "                       num_topics=k,\n",
    "                       random_state=100,                  \n",
    "                       passes=10,\n",
    "                       alpha=a,\n",
    "                       eta=b,\n",
    "                       workers=num_processors-1)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=normalized_corpus, dictionary=dictionary, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
